{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('i like you', 'pos'),\n",
    "        ('i hate you', 'neg'),\n",
    "        ('you like me', 'neg'),\n",
    "        ('i like her', 'pos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hate', 'her', 'i', 'like', 'me', 'you'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set(word.lower() for sentence in train\n",
    "               for word in word_tokenize(sentence[0]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'hate': False,\n",
       "   'her': False,\n",
       "   'i': True,\n",
       "   'like': True,\n",
       "   'me': False,\n",
       "   'you': True},\n",
       "  'pos'),\n",
       " ({'hate': True,\n",
       "   'her': False,\n",
       "   'i': True,\n",
       "   'like': False,\n",
       "   'me': False,\n",
       "   'you': True},\n",
       "  'neg'),\n",
       " ({'hate': False,\n",
       "   'her': False,\n",
       "   'i': False,\n",
       "   'like': True,\n",
       "   'me': True,\n",
       "   'you': True},\n",
       "  'neg'),\n",
       " ({'hate': False,\n",
       "   'her': True,\n",
       "   'i': True,\n",
       "   'like': True,\n",
       "   'me': False,\n",
       "   'you': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1])\n",
    "    for x in train]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                      me = False             pos : neg    =      1.7 : 1.0\n",
      "                       i = True              pos : neg    =      1.7 : 1.0\n",
      "                     you = True              neg : pos    =      1.7 : 1.0\n",
      "                    hate = False             pos : neg    =      1.7 : 1.0\n",
      "                    like = True              pos : neg    =      1.7 : 1.0\n",
      "                     her = False             neg : pos    =      1.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(t)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hate': False,\n",
       " 'her': False,\n",
       " 'i': True,\n",
       " 'like': True,\n",
       " 'me': False,\n",
       " 'you': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = 'i like Merui'\n",
    "test_sent_features = {word.lower():\n",
    "                         (word in word_tokenize(test_sentence.lower()))\n",
    "                     for word in all_words}\n",
    "test_sent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_sent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "pos_tagger = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'고양이도',\n",
       " '고양이야',\n",
       " '난',\n",
       " '놀거야',\n",
       " '마치고',\n",
       " '메리가',\n",
       " '메리는',\n",
       " '메리랑',\n",
       " '수업이',\n",
       " '이쁜',\n",
       " '좋아',\n",
       " '지루해'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = [('메리가 좋아', 'pos'),\n",
    "         ('고양이도 좋아', 'pos'),\n",
    "         ('난 수업이 지루해', 'neg'),\n",
    "         ('메리는 이쁜 고양이야', 'pos'),\n",
    "         ('난 마치고 메리랑 놀거야', 'pos')]\n",
    "\n",
    "all_words = set(word.lower() for sentence in train\n",
    "              for word in word_tokenize(sentence[0]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'고양이도': False,\n",
       "   '고양이야': False,\n",
       "   '난': False,\n",
       "   '놀거야': False,\n",
       "   '마치고': False,\n",
       "   '메리가': True,\n",
       "   '메리는': False,\n",
       "   '메리랑': False,\n",
       "   '수업이': False,\n",
       "   '이쁜': False,\n",
       "   '좋아': True,\n",
       "   '지루해': False},\n",
       "  'pos'),\n",
       " ({'고양이도': True,\n",
       "   '고양이야': False,\n",
       "   '난': False,\n",
       "   '놀거야': False,\n",
       "   '마치고': False,\n",
       "   '메리가': False,\n",
       "   '메리는': False,\n",
       "   '메리랑': False,\n",
       "   '수업이': False,\n",
       "   '이쁜': False,\n",
       "   '좋아': True,\n",
       "   '지루해': False},\n",
       "  'pos'),\n",
       " ({'고양이도': False,\n",
       "   '고양이야': False,\n",
       "   '난': True,\n",
       "   '놀거야': False,\n",
       "   '마치고': False,\n",
       "   '메리가': False,\n",
       "   '메리는': False,\n",
       "   '메리랑': False,\n",
       "   '수업이': True,\n",
       "   '이쁜': False,\n",
       "   '좋아': False,\n",
       "   '지루해': True},\n",
       "  'neg'),\n",
       " ({'고양이도': False,\n",
       "   '고양이야': True,\n",
       "   '난': False,\n",
       "   '놀거야': False,\n",
       "   '마치고': False,\n",
       "   '메리가': False,\n",
       "   '메리는': True,\n",
       "   '메리랑': False,\n",
       "   '수업이': False,\n",
       "   '이쁜': True,\n",
       "   '좋아': False,\n",
       "   '지루해': False},\n",
       "  'pos'),\n",
       " ({'고양이도': False,\n",
       "   '고양이야': False,\n",
       "   '난': True,\n",
       "   '놀거야': True,\n",
       "   '마치고': True,\n",
       "   '메리가': False,\n",
       "   '메리는': False,\n",
       "   '메리랑': True,\n",
       "   '수업이': False,\n",
       "   '이쁜': False,\n",
       "   '좋아': False,\n",
       "   '지루해': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1])\n",
    "    for x in train]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       난 = True              neg : pos    =      2.5 : 1.0\n",
      "                      좋아 = False             neg : pos    =      1.5 : 1.0\n",
      "                    고양이도 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리가 = False             neg : pos    =      1.1 : 1.0\n",
      "                     놀거야 = False             neg : pos    =      1.1 : 1.0\n",
      "                     마치고 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리랑 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리는 = False             neg : pos    =      1.1 : 1.0\n",
      "                    고양이야 = False             neg : pos    =      1.1 : 1.0\n",
      "                      이쁜 = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(t)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = '난 수업이 마치면 메리랑 놀러야'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'고양이도': False,\n",
       " '고양이야': False,\n",
       " '난': True,\n",
       " '놀거야': False,\n",
       " '마치고': False,\n",
       " '메리가': False,\n",
       " '메리는': False,\n",
       " '메리랑': True,\n",
       " '수업이': True,\n",
       " '이쁜': False,\n",
       " '좋아': False,\n",
       " '지루해': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent_features = {word.lower(): \n",
    "                     (word in word_tokenize(test_sentence.lower()))\n",
    "                     for word in all_words}\n",
    "test_sent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_sent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['메리/Noun', '가/Josa', '좋다/Adjective'], 'pos'),\n",
       " (['고양이/Noun', '도/Josa', '좋다/Adjective'], 'pos'),\n",
       " (['난/Noun', '수업/Noun', '이/Josa', '지루하다/Adjective'], 'neg'),\n",
       " (['메리/Noun', '는/Josa', '이쁘다/Adjective', '고양이/Noun', '야/Josa'], 'pos'),\n",
       " (['난/Noun', '마치/Noun', '고/Josa', '메리/Noun', '랑/Josa', '놀다/Verb'], 'pos')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs = [(tokenize(row[0]), row[1]) for row in train]\n",
    "train_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['메리/Noun',\n",
       " '가/Josa',\n",
       " '좋다/Adjective',\n",
       " '고양이/Noun',\n",
       " '도/Josa',\n",
       " '좋다/Adjective',\n",
       " '난/Noun',\n",
       " '수업/Noun',\n",
       " '이/Josa',\n",
       " '지루하다/Adjective',\n",
       " '메리/Noun',\n",
       " '는/Josa',\n",
       " '이쁘다/Adjective',\n",
       " '고양이/Noun',\n",
       " '야/Josa',\n",
       " '난/Noun',\n",
       " '마치/Noun',\n",
       " '고/Josa',\n",
       " '메리/Noun',\n",
       " '랑/Josa',\n",
       " '놀다/Verb']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [t for d in train_docs for t in d[0]]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_exists(doc):\n",
    "    return {word: (word in set(doc)) for word in tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'가/Josa': True,\n",
       "   '고/Josa': False,\n",
       "   '고양이/Noun': False,\n",
       "   '난/Noun': False,\n",
       "   '놀다/Verb': False,\n",
       "   '는/Josa': False,\n",
       "   '도/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '메리/Noun': True,\n",
       "   '수업/Noun': False,\n",
       "   '야/Josa': False,\n",
       "   '이/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '좋다/Adjective': True,\n",
       "   '지루하다/Adjective': False},\n",
       "  'pos'),\n",
       " ({'가/Josa': False,\n",
       "   '고/Josa': False,\n",
       "   '고양이/Noun': True,\n",
       "   '난/Noun': False,\n",
       "   '놀다/Verb': False,\n",
       "   '는/Josa': False,\n",
       "   '도/Josa': True,\n",
       "   '랑/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '메리/Noun': False,\n",
       "   '수업/Noun': False,\n",
       "   '야/Josa': False,\n",
       "   '이/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '좋다/Adjective': True,\n",
       "   '지루하다/Adjective': False},\n",
       "  'pos'),\n",
       " ({'가/Josa': False,\n",
       "   '고/Josa': False,\n",
       "   '고양이/Noun': False,\n",
       "   '난/Noun': True,\n",
       "   '놀다/Verb': False,\n",
       "   '는/Josa': False,\n",
       "   '도/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '메리/Noun': False,\n",
       "   '수업/Noun': True,\n",
       "   '야/Josa': False,\n",
       "   '이/Josa': True,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '좋다/Adjective': False,\n",
       "   '지루하다/Adjective': True},\n",
       "  'neg'),\n",
       " ({'가/Josa': False,\n",
       "   '고/Josa': False,\n",
       "   '고양이/Noun': True,\n",
       "   '난/Noun': False,\n",
       "   '놀다/Verb': False,\n",
       "   '는/Josa': True,\n",
       "   '도/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '메리/Noun': True,\n",
       "   '수업/Noun': False,\n",
       "   '야/Josa': True,\n",
       "   '이/Josa': False,\n",
       "   '이쁘다/Adjective': True,\n",
       "   '좋다/Adjective': False,\n",
       "   '지루하다/Adjective': False},\n",
       "  'pos'),\n",
       " ({'가/Josa': False,\n",
       "   '고/Josa': True,\n",
       "   '고양이/Noun': False,\n",
       "   '난/Noun': True,\n",
       "   '놀다/Verb': True,\n",
       "   '는/Josa': False,\n",
       "   '도/Josa': False,\n",
       "   '랑/Josa': True,\n",
       "   '마치/Noun': True,\n",
       "   '메리/Noun': True,\n",
       "   '수업/Noun': False,\n",
       "   '야/Josa': False,\n",
       "   '이/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '좋다/Adjective': False,\n",
       "   '지루하다/Adjective': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xy = [(term_exists(d), c) for d,c in train_docs]\n",
    "train_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = [('난 수업이 마치면 메리랑 놀거야')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('난', 'Noun'),\n",
       " ('수업', 'Noun'),\n",
       " ('이', 'Josa'),\n",
       " ('마치', 'Noun'),\n",
       " ('면', 'Josa'),\n",
       " ('메리', 'Noun'),\n",
       " ('랑', 'Josa'),\n",
       " ('놀거', 'Verb'),\n",
       " ('야', 'Eomi')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_docs = pos_tagger.pos(test_sentence[0])\n",
    "test_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('난', 'Noun'): False,\n",
       " ('놀거', 'Verb'): False,\n",
       " ('랑', 'Josa'): False,\n",
       " ('마치', 'Noun'): False,\n",
       " ('메리', 'Noun'): False,\n",
       " ('면', 'Josa'): False,\n",
       " ('수업', 'Noun'): False,\n",
       " ('야', 'Eomi'): False,\n",
       " ('이', 'Josa'): False}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent_features = {word: (word in tokens) for word in test_docs}\n",
    "test_sent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_sent_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
